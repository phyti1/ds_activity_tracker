{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from math import sin, cos, sqrt, atan2, radians\n",
    "import scipy as sp\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from gitlab.client import Gitlab as gl\n",
    "#import xgboost as xgb\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ShouldRunModels():\n",
    "    try:\n",
    "        value = gl.variables.get('run_models')\n",
    "        if(value == 0):\n",
    "            return False\n",
    "        else:\n",
    "            return True\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "run_mdls = ShouldRunModels()\n",
    "# manually set if needed\n",
    "# run_mdls = True\n",
    "\n",
    "print(run_mdls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean = pd.read_csv(\"../Analyse/df_clean.csv\")\n",
    "df_clean = df_clean.drop(columns=['Unnamed: 0'])\n",
    "df_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean['time'] = pd.to_datetime(df_clean['time'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean['name'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean.iloc[:, 3:18].hist(figsize=(22, 10), bins=50)\n",
    "# tite wie?\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hier wird ersichtlich, dass keine der Varialben normalverteilt ist. Trotzdem wird in Folge versucht, Ausreisser mittels Boxplots zu itentifizieren."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 4, figsize=(22, 8))\n",
    "axs = axs.flatten()\n",
    "for i in range(3):\n",
    "    axs[i].set_title([\"accelometer\", \"magnetometer\", \"gyroscope\"][i])\n",
    "    axs[i].boxplot(df_clean.iloc[:, i*3 + 3 : i*3 + 6])\n",
    "    #axs[i] = sns.swarmplot(data=df_clean.iloc[:, i*3 + 3 : i*3 + 6], color=\"grey\")\n",
    "\n",
    "axs[3].set_title(\"orientation\")\n",
    "axs[3].boxplot(df_clean.iloc[:, 12:16])\n",
    "# axs[4].set_title(\"gps\")\n",
    "# axs[4].boxplot(df_clean.iloc[:, 16:18])\n",
    "\n",
    "fig.suptitle(\"Verteilung numerischer Daten\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Um die Achsen der Daten im Modell nicht einzubeziehen sollen diese miteinander verrechnet werden. Dafür machen wir die Werte positiv und addieren sie auf. Da alle Achsen gleich skaliert werden sollen, wird anstelle einer Normailsierung mit einem konstanten Wert addiert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accelometer\n",
    "df_clean['acc'] = (df_clean.iloc[:, 3:6] + 10).sum(axis=1)\n",
    "# magnetometer\n",
    "df_clean['mag'] = (df_clean.iloc[:, 6:9] + 2000).sum(axis=1)\n",
    "# gyroscope\n",
    "df_clean['gyr'] = (df_clean.iloc[:, 9:12] + 30).sum(axis=1)\n",
    "# orientation\n",
    "df_clean['ori'] = (df_clean.iloc[:, 12:16] + 1).sum(axis=1)\n",
    "\n",
    "# drop old axis columns\n",
    "df_clean.drop(columns=df_clean.columns[3:16], inplace=True)\n",
    "df_clean.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(df_clean.iloc[:, 3:] < 0).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wie hier sichtbar wird sind keine negativen Sensorwerte mehr vorhanden. Dies ist gut so."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean.iloc[:, 3:].hist(figsize=(22, 7), bins=50)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sinnvoller als Koordinatendaten wäre Geschwindigkeit. Denn auf den Ort soll nicht zurückgeschlossen werden. Dafür werden hier die Koordinaten Unterschiede berechnet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gps_diff = (df_clean.loc[:, [\"lat\", \"long\"]] - df_clean.loc[:, [\"lat\", \"long\"]].shift(-1))\n",
    "gps_diff.replace(0, np.NAN, inplace=True)\n",
    "gps_diff[(abs(gps_diff) < 1e-3)].hist(bins=50, figsize=(22, 5))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Werte ausserhalb diese Bereichs werden als Ausreisser betrachtet und deshalb hier entfernt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gps_diff[abs(gps_diff) > 1e-3] = np.NAN\n",
    "gps_diff.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gps_diff.notna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean[\"gps_differs\"] = (df_clean[[\"lat\", \"long\"]] - df_clean[[\"lat\", \"long\"]].shift(-1)).sum(axis=1).astype(bool)\n",
    "df_clean[\"gps_differs\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate distance in meters (https://stackoverflow.com/questions/57294120/calculating-distance-between-latitude-and-longitude-in-python)\n",
    "\n",
    "i = 0\n",
    "\n",
    "def get_distance(point1, point2):\n",
    "    if(point1[0] == point2[0] and point1[1] == point2[1]):\n",
    "        return 0.0\n",
    "\n",
    "    R = 6370\n",
    "    lat1 = radians(point1[0])  #insert value\n",
    "    lon1 = radians(point1[1])\n",
    "    lat2 = radians(point2[0])\n",
    "    lon2 = radians(point2[1])\n",
    "\n",
    "    dlon = lon2 - lon1\n",
    "    dlat = lat2- lat1\n",
    "\n",
    "    a = sin(dlat / 2)**2 + cos(lat1) * cos(lat2) * sin(dlon / 2)**2\n",
    "    c = 2 * atan2(sqrt(a), sqrt(1-a))\n",
    "    distance = R * c\n",
    "    return distance\n",
    "\n",
    "dists = []\n",
    "gps_differs_index = df_clean.loc[df_clean[\"gps_differs\"] == True, \"gps_differs\"].index\n",
    "for i in range(gps_differs_index.shape[0]):\n",
    "    dists.append(get_distance(df_clean.loc[gps_differs_index[i], [\"lat\", \"long\"]], df_clean.loc[gps_differs_index[i]+1, [\"lat\", \"long\"]]))\n",
    "\n",
    "    i = i+1\n",
    "    if(i % 10000 == 0):\n",
    "        print(f\"{round(i/gps_differs_index.shape[0] * 100)}%\")\n",
    "\n",
    "len(dists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verteilung der dists\n",
    "dists = pd.Series(dists)\n",
    "dists[(dists < 1)].hist(bins=50)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate time differences\n",
    "time_differences = pd.Series(df_clean.loc[gps_differs_index, \"time\"].values - df_clean.loc[gps_differs_index.insert(0, 0)[:-1], \"time\"].values)\n",
    "time_diff_secs = time_differences.dt.total_seconds()\n",
    "\n",
    "time_diff_secs[(time_diff_secs < 15) & (time_diff_secs > -10)].hist(bins=50)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Das Zeitintervall der GPS Messungen ist etwa 1s. Um falsche Werte zu verwerfen werden diese auf 0 gesetzt, später durch 0 dividiert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(time_diff_secs[(time_diff_secs > 15) | (time_diff_secs < -10)].shape)\n",
    "time_diff_secs.loc[(time_diff_secs > 10) | (time_diff_secs < 0)] = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# m/s ausrechen, in km/h umrechnen\n",
    "kmh = (dists / time_diff_secs * 3.6)\n",
    "kmh[kmh == np.inf] = np.nan\n",
    "kmh[kmh > 120] = np.nan\n",
    "kmh[kmh < 1] = 0\n",
    "kmh[kmh > 0].hist(bins=50)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# geschwindigkeit inseriteren\n",
    "df_clean.loc[gps_differs_index, \"kmh\"] = kmh\n",
    "df_clean.drop(columns=[\"lat\", \"long\", \"gps_differs\"], inplace=True)\n",
    "df_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# forward fill\n",
    "df_clean[\"kmh\"] = df_clean[\"kmh\"].ffill().fillna(0)\n",
    "df_clean.hist(figsize=(22, 7), bins=50)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filter nach 5sec Abschnitte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_time = pd.to_datetime(\"01.01.2021 00:00:00\")\n",
    "\n",
    "df_clean[\"5s_index\"] = (df_clean[\"time\"] - old_time).dt.total_seconds() // 5 * 5\n",
    "# df_clean[\"5s_index\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wind = df_clean.groupby(\"5s_index\")\n",
    "# print group count\n",
    "print(df_wind.size().count())\n",
    "# count elements per group\n",
    "df_wind.size().hist(figsize=(22, 5), bins=50)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Als nächstes wird geprüft, ob Elemente mit mehreren Namen existieren, sich dieser also in 5s geändert hat. Diese werden in Folge entfernt, da es nur wenige Werte sind."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wind[\"name\"].nunique().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_wind.size().count())\n",
    "df_wind = df_wind.filter(lambda g: g[\"name\"].nunique() == 1).groupby(\"5s_index\")\n",
    "print(df_wind.size().count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean.columns[3:8].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = df_wind[[\"name\", \"activity\"]].first().reset_index()\n",
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_agg = df_wind[df_clean.columns[3:8]].agg([\"var\", \"mean\", \"median\", \"min\", \"max\"]).reset_index()\n",
    "np.array(df_agg.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# flatten mutli index columns\n",
    "df_agg.columns = ['_'.join(column) for column in df_agg.columns]\n",
    "df_agg.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add target variables\n",
    "if(\"activity\" not in df_agg.columns):\n",
    "    df_agg = pd.concat([df_agg, target], axis=1)\n",
    "df_agg.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_agg.iloc[:, :-2].columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  check for NA's\n",
    "df_agg.isna().sum()[df_agg.isna().sum() > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inputation von 0, da Varianz 0 keine Varianz darstellt.\n",
    "df_agg = df_agg.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_agg.iloc[:, :-2], df_agg[\"activity\"], test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if(run_mdls):\n",
    "    log_range = np.logspace(0, 3, 10) / 1e+3 / 1\n",
    "    model = RandomForestClassifier(n_jobs = -1, oob_score=True, warm_start=True)\n",
    "    param_grid = {\n",
    "        'n_estimators': [200, 250, 300],\n",
    "        'max_depth': [35, 40, 45],\n",
    "        'ccp_alpha': list(log_range / 100),\n",
    "    }\n",
    "    # scoring definition from https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter\n",
    "    rs = RandomizedSearchCV(estimator=model, param_distributions=param_grid, cv=5, scoring='f1_weighted', n_iter=1, verbose=1, random_state=42)\n",
    "    # fit on all data\n",
    "    rs.fit(X_train, y_train)\n",
    "\n",
    "else:\n",
    "    rs = pickle.load(open('../models/rf_allprop.pkl', 'rb'))\n",
    "\n",
    "print(\"\")\n",
    "print(f'Random Forest refit weighted f1:        {rs.score(X_test, y_test)}')\n",
    "print(f'Random Forest best cv mean weighted f1: {rs.best_score_}')\n",
    "print(f'Random Forest best parameters:          {rs.best_estimator_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion(y_test, y_pred):\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(10, 10))\n",
    "    im = ax.matshow(conf_matrix, cmap=plt.cm.Greens, alpha=0.8)\n",
    "    for row in range(conf_matrix.shape[0]):\n",
    "        for col in range(conf_matrix.shape[1]):\n",
    "            ax.text(x=col, y = row, s = conf_matrix[row, col], va='center', ha='center', size='xx-large')\n",
    "\n",
    "    ax.tick_params(axis=\"x\", rotation=30)\n",
    "    classes = np.unique(df_agg[\"activity\"].unique())\n",
    "    plt.xticks(np.arange(0,len(classes)), classes)\n",
    "    plt.yticks(np.arange(0,len(classes)), classes)\n",
    "    plt.xlabel('Predictions', fontsize=18)\n",
    "    plt.ylabel('Actuals', fontsize=18)\n",
    "    plt.title('Confusion Matrix', fontsize=18)\n",
    "    plt.colorbar(im, shrink=0.825)\n",
    "    plt.show()\n",
    "\n",
    "plot_confusion(y_test, rs.predict(X_test))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0adc1ef09d917064b92916def966acef0068b55e2d00bed911d51b16105d0b4e"
  },
  "kernelspec": {
   "display_name": "Python 3.9.4 ('git_repo-G3UKNH-B')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
